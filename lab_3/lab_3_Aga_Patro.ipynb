{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aga Patro - lab 3"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 1. Implementacja algorytmu obliczania odległości edycyjnej"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein_distance(word_1, word_2):\n",
    "    m = len(word_1)\n",
    "    n = len(word_2)\n",
    "    result_matrix = [[0 for j in range(n+1)] for i in range(m+1)]\n",
    "\n",
    "    for i in range(0, m + 1):\n",
    "        result_matrix[i][0] = i\n",
    "    for j in range(0, n + 1):\n",
    "        result_matrix[0][j] = j\n",
    "\n",
    "    for i in range(1, m + 1):\n",
    "        for j in range(1, n + 1):\n",
    "            if word_1[i - 1] == word_2[j - 1]:\n",
    "                result_matrix[i][j] = result_matrix[i - 1][j - 1]\n",
    "            else:\n",
    "                result_matrix[i][j] = min(result_matrix[i - 1][j], \n",
    "                                          result_matrix[i][j - 1], \n",
    "                                          result_matrix[i - 1][j - 1]) + 1\n",
    "\n",
    "    return result_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "word_1 = 'matematyka'\n",
    "word_2 = 'informatyka'\n",
    "print(levenshtein_distance(word_1, word_2)[-1][-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 2. Wizualizacja działania algorytmu Levenshteina"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edit_operations(word_1, word_2, edit_matrix):\n",
    "    operations = []\n",
    "    position = []\n",
    "    n = len(word_1)\n",
    "    m = len(word_2)\n",
    "\n",
    "    while n > 0 or m > 0:\n",
    "        if edit_matrix[n - 1][m] + 1 == edit_matrix[n][m]:\n",
    "            operations.append(\"Removed\")\n",
    "            n -= 1\n",
    "        elif edit_matrix[n][m - 1] + 1 == edit_matrix[n][m]:\n",
    "            operations.append(\"Added\")\n",
    "            m -= 1\n",
    "        elif edit_matrix[n - 1][m - 1] == edit_matrix[n][m]:\n",
    "            operations.append(\"No changes\")\n",
    "            n -= 1\n",
    "            m -= 1\n",
    "        else:\n",
    "            operations.append(\"Replaced\")\n",
    "            n -= 1\n",
    "            m -= 1\n",
    "\n",
    "        position.append(m)\n",
    "    \n",
    "    position.reverse()\n",
    "    operations.reverse()\n",
    "    \n",
    "    return operations, position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualization(word_1, word_2, operations, edit_nb):\n",
    "    i = 0\n",
    "    j = 0\n",
    "    print(f\"To get word {word_2} from word {word_1} you need to do {edit_nb} operations: \\n\")\n",
    "\n",
    "    for operation in operations:\n",
    "        if operation == 'Added':\n",
    "            print(f\"Add {word_2[j]}: {word_1[:j]}[{word_2[j]}]{word_1[j:]}\\n\")\n",
    "            word_1 = word_1[:j] + word_2[j] + word_1[j:]\n",
    "        elif operation == 'Removed':\n",
    "            print(f\"Remove {word_1[i]}: {word_1[:i]}[{word_1[i]}]{word_1[i + 1:]}\\n\")\n",
    "            word_1 = word_1[:i] + word_1[i + 1:]\n",
    "            continue\n",
    "        elif operation == 'Replaced':\n",
    "            print(f\"Replace {word_1[i]} with {word_2[j]}: {word_1[:i]}[{word_1[i]} -> {word_2[j]}]{word_1[i + 1:]} \\n\")\n",
    "            word_1 = word_1[:j] + word_2[j] + word_1[j + 1:]\n",
    "        i += 1\n",
    "        j += 1\n",
    "    \n",
    "    if word_1 == word_2:\n",
    "        print(f\"Success! Now first word is: {word_1}, which is the same as second word: {word_2}! \\n\")\n",
    "    else:\n",
    "        print(f\"Ups, something went wrong :( \\n\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 3. Testy działania algorytmu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_levenshtein(word_1, word_2):\n",
    "    edit_matrix = levenshtein_distance(word_1, word_2)\n",
    "    operations, _ = get_edit_operations(word_1, word_2, edit_matrix)\n",
    "    visualization(word_1, word_2, operations, edit_matrix[-1][-1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 los - kloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get word kloc from word los you need to do 2 operations: \n",
      "\n",
      "Add k: [k]los\n",
      "\n",
      "Replace s with c: klo[s -> c] \n",
      "\n",
      "Success! Now first word is: kloc, which is the same as second word: kloc! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_levenshtein('los', 'kloc')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Łódź - Lodz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get word Lodz from word Łódź you need to do 3 operations: \n",
      "\n",
      "Replace Ł with L: [Ł -> L]ódź \n",
      "\n",
      "Replace ó with o: L[ó -> o]dź \n",
      "\n",
      "Replace ź with z: Lod[ź -> z] \n",
      "\n",
      "Success! Now first word is: Lodz, which is the same as second word: Lodz! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_levenshtein('Łódź', 'Lodz')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 kwintesencja - quintessence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get word quintessence from word kwintesencja you need to do 5 operations: \n",
      "\n",
      "Replace k with q: [k -> q]wintesencja \n",
      "\n",
      "Replace w with u: q[w -> u]intesencja \n",
      "\n",
      "Add s: quintes[s]encja\n",
      "\n",
      "Replace j with e: quintessenc[j -> e]a \n",
      "\n",
      "Remove a: quintessence[a]\n",
      "\n",
      "Success! Now first word is: quintessence, which is the same as second word: quintessence! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_levenshtein('kwintesencja', 'quintessence')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 ATGAATCTTACCGCCTCG - ATGAGGCTCTGGCCCCTG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get word ATGAGGCTCTGGCCCCTG from word ATGAATCTTACCGCCTCG you need to do 7 operations: \n",
      "\n",
      "Replace A with G: ATGA[A -> G]TCTTACCGCCTCG \n",
      "\n",
      "Replace T with G: ATGAG[T -> G]CTTACCGCCTCG \n",
      "\n",
      "Add C: ATGAGGCT[C]TACCGCCTCG\n",
      "\n",
      "Replace A with G: ATGAGGCTCT[A -> G]CCGCCTCG \n",
      "\n",
      "Add G: ATGAGGCTCTG[G]CCGCCTCG\n",
      "\n",
      "Remove G: ATGAGGCTCTGGCC[G]CCTCG\n",
      "\n",
      "Remove C: ATGAGGCTCTGGCCCCT[C]G\n",
      "\n",
      "Success! Now first word is: ATGAGGCTCTGGCCCCTG, which is the same as second word: ATGAGGCTCTGGCCCCTG! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_levenshtein('ATGAATCTTACCGCCTCG', 'ATGAGGCTCTGGCCCCTG')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 4. Implementacja algorytmu znajdującego najdłuższe wspólne podsłowo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def longest_common_subsequence(word_1, word_2):\n",
    "    m = len(word_1)\n",
    "    n = len(word_2)\n",
    "    matrix = [[0 for j in range(n+1)] for i in range(m+1)]\n",
    "    max_length = 0\n",
    "\n",
    "    for i in range(1, m):\n",
    "        for j in range(1, n):\n",
    "            if word_1[i] == word_2[j]:\n",
    "                matrix[i][j] = matrix[i-1][j-1] + 1\n",
    "                max_length = max(max_length, matrix[i][j])\n",
    "            else:\n",
    "                matrix[i][j] = 0\n",
    "\n",
    "    return max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "word_1 = 'matematyka'\n",
    "word_2 = 'informatyka'\n",
    "print(longest_common_subsequence(word_1, word_2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 5. Podział \"romeo-i-julia-700.txt\" na tokeny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.pl import Polish\n",
    "\n",
    "def create_tokens():\n",
    "    language = Polish()\n",
    "    tokenizer = Tokenizer(language.vocab)\n",
    "    \n",
    "    with open(\"romeo-i-julia-700.txt\", 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    token = tokenizer(text)\n",
    "    \n",
    "    return token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 6. Stworzenie 2 wersji załączonego tekstu, w których usunięto 3% losowych tokenów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def delete_lines(tokens, percent=3):\n",
    "    result = []\n",
    "    for token in tokens:\n",
    "        if random.random() > percent/100:\n",
    "            result.append(token)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def create_files(tokens):\n",
    "    tokens1 = delete_lines(tokens)\n",
    "    tokens2 = delete_lines(tokens)\n",
    "\n",
    "    with open('text1.txt', 'w', encoding='utf-8') as file1:\n",
    "        for token in tokens1:\n",
    "            file1.write(token.text_with_ws)\n",
    "\n",
    "    with open('text2.txt', 'w', encoding='utf-8') as file2:\n",
    "        for token in tokens2:\n",
    "            file2.write(token.text_with_ws)\n",
    "\n",
    "    return tokens1, tokens2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = create_tokens()\n",
    "tokens1, tokens2 = create_files(tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 7. Długość najdłuższego podciągu wspólnych tokenów stworzonych tekstów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The longest common tokens subsequence: 99 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"The longest common tokens subsequence: {longest_common_subsequence(tokens1, tokens2)} \\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 8. git --diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sth_like_diff(file_1, file_2):\n",
    "    with open(file_1, 'r', encoding=\"utf8\") as file:\n",
    "        text1 = file.read()\n",
    "    \n",
    "    with open(file_2, 'r', encoding=\"utf8\") as file:\n",
    "        text2 = file.read()\n",
    "\n",
    "    text1 = text1.split('\\n')\n",
    "    text2 = text2.split('\\n')\n",
    "\n",
    "    matrix = levenshtein_distance(text1, text2)\n",
    "    path, pos = get_edit_operations(text1, text2, matrix)\n",
    "\n",
    "    x = 0\n",
    "        \n",
    "    for j in range(len(path)):\n",
    "        op = path[j]\n",
    "        i = pos[j]\n",
    "        if op == 'Added':\n",
    "            print(\"+ ({})  \".format(i + 1) + text1[i])\n",
    "            x -= 1\n",
    "        elif op == 'Removed':\n",
    "            print(\"- ({})  \".format(i + x + 1) + text2[i + x])\n",
    "            x += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zadanie 9. Porównanie tesktów za pomocą git --diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- (38)  \n",
      "- (43)  Do nowej zbrodni pchają złości dawne,\n",
      "- (44)  Plamiąc szlachetną krwią szlachetne dłonie\n",
      "+ (45)  Tam, gdzie się rzecz ta rozgrywa, w Weronie,\n",
      "+ (46)  Do nowej zbrodni pchają złości dawne,\n",
      "+ (162)  \n",
      "+ (163)  Nie bój się.\n",
      "+ (164)  \n",
      "- (191)  \n",
      "+ (211)  SAMSON\n",
      "- (211)  Nie, mości panie; nie się na was, tylko skrzywiłem się tak sobie.\n",
      "- (216)  / do Abrahama /\n",
      "+ (277)  \n",
      "+ (364)  Pod karą śmierci, aby się rozeszli.\n",
      "+ (386)  Aż książę nadszedł i rozdzielił wszystkich.\n",
      "- (420)  Łzami poranną mnożącego rosę,\n",
      "- (439)  Nie znam i z niego wydobyć nie mogę.BENWOLIO\n",
      "- (440)  \n",
      "- (441)  Wybadywał żeś go jakim sposobem?\n",
      "- (513)  BENWOLIO\n",
      "- (515)                          Jak to? brak miłości?\n",
      "+ (542)  Odpychająca! Poważna pustoto!Szpetny chaosie wdzięków! Ciężki puchu!\n",
      "- (568)  Współczucie twoje nad moim cierpieniem\n",
      "+ (626)  \n",
      "+ (627)  \n",
      "+ (637)  ROMEOA właśnieś chybił. Niczym tu kołczany\n",
      "+ (638)  Kupida; ona ma naturę Diany;\n",
      "- (646)  kiedy umrze, do z nią zstąpiCałe którego tak skąpi.\n",
      "+ (679)  \n"
     ]
    }
   ],
   "source": [
    "sth_like_diff('text1.txt', 'text2.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
